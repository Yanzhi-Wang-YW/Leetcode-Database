```md
1321. Restaurant Growth 
Table: Customer

+---------------+---------+
| Column Name   | Type    |
+---------------+---------+
| customer_id   | int     |
| name          | varchar |
| visited_on    | date    |
| amount        | int     |
+---------------+---------+
In SQL,(customer_id, visited_on) is the primary key for this table.
This table contains data about customer transactions in a restaurant.
visited_on is the date on which the customer with ID (customer_id) has visited the restaurant.
amount is the total paid by a customer.
 

You are the restaurant owner and you want to analyze a possible expansion (there will be at least one customer every day).

Compute the moving average of how much the customer paid in a seven days window (i.e., current day + 6 days before). average_amount should be rounded to two decimal places.

Return the result table ordered by visited_on in ascending order.

The result format is in the following example.

 

Example 1:

Input: 
Customer table:
+-------------+--------------+--------------+-------------+
| customer_id | name         | visited_on   | amount      |
+-------------+--------------+--------------+-------------+
| 1           | Jhon         | 2019-01-01   | 100         |
| 2           | Daniel       | 2019-01-02   | 110         |
| 3           | Jade         | 2019-01-03   | 120         |
| 4           | Khaled       | 2019-01-04   | 130         |
| 5           | Winston      | 2019-01-05   | 110         | 
| 6           | Elvis        | 2019-01-06   | 140         | 
| 7           | Anna         | 2019-01-07   | 150         |
| 8           | Maria        | 2019-01-08   | 80          |
| 9           | Jaze         | 2019-01-09   | 110         | 
| 1           | Jhon         | 2019-01-10   | 130         | 
| 3           | Jade         | 2019-01-10   | 150         | 
+-------------+--------------+--------------+-------------+
Output: 
+--------------+--------------+----------------+
| visited_on   | amount       | average_amount |
+--------------+--------------+----------------+
| 2019-01-07   | 860          | 122.86         |
| 2019-01-08   | 840          | 120            |
| 2019-01-09   | 840          | 120            |
| 2019-01-10   | 1000         | 142.86         |
+--------------+--------------+----------------+
Explanation: 
1st moving average from 2019-01-01 to 2019-01-07 has an average_amount of (100 + 110 + 120 + 130 + 110 + 140 + 150)/7 = 122.86
2nd moving average from 2019-01-02 to 2019-01-08 has an average_amount of (110 + 120 + 130 + 110 + 140 + 150 + 80)/7 = 120
3rd moving average from 2019-01-03 to 2019-01-09 has an average_amount of (120 + 130 + 110 + 140 + 150 + 80 + 110)/7 = 120
4th moving average from 2019-01-04 to 2019-01-10 has an average_amount of (130 + 110 + 140 + 150 + 80 + 110 + 130 + 150)/7 = 142.86
```

```py
import pandas as pd

def restaurant_growth(customer: pd.DataFrame) -> pd.DataFrame:
    customer['visited_on'] = pd.to_datetime(customer['visited_on']) 
    customTransformations1 = customer

    customTransformations1 = customTransformations1.sort_values('visited_on', ascending=True) 
    customTransformations2 = customTransformations1

    customTransformations2 = customTransformations2.groupby('visited_on').agg(
    total_amount=('amount', 'sum')
    ).reset_index() 
    customTransformations3 = customTransformations2

    customTransformations3['rolling_sum'] = customTransformations3['total_amount'].rolling(window=7, min_periods=7).sum()
    customTransformations3['rolling_mean'] = customTransformations3['total_amount'].rolling(window=7, min_periods=7).mean().round(2) 
    customTransformations4 = customTransformations3   




    customTransformations4 = customTransformations4[['visited_on', 'rolling_sum', 'rolling_mean']]
    customTransformations5 = customTransformations4

    customTransformations5 = customTransformations5.rename(columns={'rolling_sum': 'amount'}) 
    customTransformations5 = customTransformations5.rename(columns={'rolling_mean': 'average_amount'}) 
    customTransformations6 = customTransformations5

    customTransformations6 = customTransformations6.dropna()
    customTransformations7 = customTransformations6 
    output = customTransformations7   
    return output 
``` 
## Here is the step-by-step table flowchart with the corresponding Python code for each stage of your data transformation pipeline.

### **Step 1: Load and Convert Dates**
The data is loaded, and the `visited_on` column is converted from a string to a datetime object to allow for proper sorting and calculations.

**Python Code:**
```python
inlineInput1['visited_on'] = pd.to_datetime(inlineInput1['visited_on'])
customTransformations1 = inlineInput1
```

**Table Output (`customTransformations1`):**
*(Note: `visited_on` is now a Datetime object)*
| customer_id | name | visited_on | amount |
| :--- | :--- | :--- | :--- |
| 1 | Jhon | 2019-01-01 | 100 |
| 2 | Daniel | 2019-01-02 | 110 |
| 3 | Jade | 2019-01-03 | 120 |
| 4 | Khaled | 2019-01-04 | 130 |
| 5 | Winston | 2019-01-05 | 110 |
| 6 | Elvis | 2019-01-06 | 140 |
| 7 | Anna | 2019-01-07 | 150 |
| 8 | Maria | 2019-01-08 | 80 |
| 9 | Jaze | 2019-01-09 | 110 |
| 1 | Jhon | 2019-01-10 | 130 |
| 3 | Jade | 2019-01-10 | 150 |

---

### **Step 2: Sort by Date**
The DataFrame is sorted by the `visited_on` column to ensure data is in chronological order.

**Python Code:**
```python
customTransformations1 = customTransformations1.sort_values('visited_on', ascending=True)
customTransformations2 = customTransformations1
```

**Table Output (`customTransformations2`):**
| customer_id | name | visited_on | amount |
| :--- | :--- | :--- | :--- |
| 1 | Jhon | 2019-01-01 | 100 |
| 2 | Daniel | 2019-01-02 | 110 |
| 3 | Jade | 2019-01-03 | 120 |
| ... | ... | ... | ... |
| 1 | Jhon | 2019-01-10 | 130 |
| 3 | Jade | 2019-01-10 | 150 |

---

### **Step 3: Group and Aggregate**
The data is grouped by `visited_on`. The amounts for each day are summed. Note that 2019-01-10 has two entries, which are combined.

**Python Code:**
```python
customTransformations2 = customTransformations2.groupby('visited_on').agg(
  total_amount=('amount', 'sum')
).reset_index()
```

**Table Output (`customTransformations3`):**
| visited_on | total_amount |
| :--- | :--- |
| 2019-01-01 | 100 |
| 2019-01-02 | 110 |
| 2019-01-03 | 120 |
| 2019-01-04 | 130 |
| 2019-01-05 | 110 |
| 2019-01-06 | 140 |
| 2019-01-07 | 150 |
| 2019-01-08 | 80 |
| 2019-01-09 | 110 |
| 2019-01-10 | 280 |

---

### **Step 4: Calculate Rolling Statistics**
A 7-day rolling window is applied.
*   **Rolling Sum**: Sum of `total_amount` for the current day and the previous 6 days.
*   **Rolling Mean**: Average of `total_amount` for the same window.
*   `min_periods=7` ensures that calculations are only performed when there are at least 7 days of data available.

**Python Code:**
```python
customTransformations3['rolling_sum'] = customTransformations3['total_amount'].rolling(window=7, min_periods=7).sum()
customTransformations3['rolling_mean'] = customTransformations3['total_amount'].rolling(window=7, min_periods=7).mean()
```

**Table Output (`customTransformations4`):**
| visited_on | total_amount | **rolling_sum** | **rolling_mean** |
| :--- | :--- | :--- | :--- |
| 2019-01-01 | 100 | NaN | NaN |
| 2019-01-02 | 110 | NaN | NaN |
| 2019-01-03 | 120 | NaN | NaN |
| 2019-01-04 | 130 | NaN | NaN |
| 2019-01-05 | 110 | NaN | NaN |
| 2019-01-06 | 140 | NaN | NaN |
| 2019-01-07 | 150 | **860** | **122.857** |
| 2019-01-08 | 80 | **840** | **120.000** |
| 2019-01-09 | 110 | **840** | **120.000** |
| 2019-01-10 | 280 | **1010** | **144.285** |

---

### **Step 5: Select Columns**
Only the `visited_on`, `rolling_sum`, and `rolling_mean` columns are kept. The `total_amount` column is discarded.

**Python Code:**
```python
customTransformations4 = customTransformations4[['visited_on', 'rolling_sum', 'rolling_mean']]
```

**Table Output (`customTransformations5`):**
| visited_on | rolling_sum | rolling_mean |
| :--- | :--- | :--- |
| 2019-01-01 | NaN | NaN |
| 2019-01-02 | NaN | NaN |
| ... | ... | ... |
| 2019-01-10 | 1010 | 144.285 |

---

### **Step 6: Rename Columns**
The columns are renamed to match the final desired schema: `rolling_sum` becomes `amount` and `rolling_mean` becomes `average_amount`.

**Python Code:**
```python
customTransformations5 = customTransformations5.rename(columns={'rolling_sum': 'amount'})
customTransformations5 = customTransformations5.rename(columns={'rolling_mean': 'average_amount'})
```

**Table Output (`customTransformations6`):**
| visited_on | **amount** | **average_amount** |
| :--- | :--- | :--- |
| 2019-01-01 | NaN | NaN |
| ... | ... | ... |
| 2019-01-10 | 1010 | 144.285 |

---

### **Step 7: Drop Missing Values**
Rows containing `NaN` (Not a Number) values are removed. Since `min_periods=7`, the first 6 days are dropped, leaving only the days with a full 7-day window calculation.

**Python Code:**
```python
customTransformations6 = customTransformations6.dropna()
```

**Final Table Output (`customTransformations7`):**
| visited_on | amount | average_amount |
| :--- | :--- | :--- |
| 2019-01-07 | 860 | 122.857143 |
| 2019-01-08 | 840 | 120.000000 |
| 2019-01-09 | 840 | 120.000000 |
| 2019-01-10 | 1010 | 144.285714 | 
