```md
1225. Report Contiguous Dates  
Table: Failed

+--------------+---------+
| Column Name  | Type    |
+--------------+---------+
| fail_date    | date    |
+--------------+---------+
fail_date is the primary key (column with unique values) for this table.
This table contains the days of failed tasks.
 

Table: Succeeded

+--------------+---------+
| Column Name  | Type    |
+--------------+---------+
| success_date | date    |
+--------------+---------+
success_date is the primary key (column with unique values) for this table.
This table contains the days of succeeded tasks.
 

A system is running one task every day. Every task is independent of the previous tasks. The tasks can fail or succeed.

Write a solution to report the period_state for each continuous interval of days in the period from 2019-01-01 to 2019-12-31.

period_state is 'failed' if tasks in this interval failed or 'succeeded' if tasks in this interval succeeded. Interval of days are retrieved as start_date and end_date.

Return the result table ordered by start_date.

The result format is in the following example.

 

Example 1:

Input: 
Failed table:
+-------------------+
| fail_date         |
+-------------------+
| 2018-12-28        |
| 2018-12-29        |
| 2019-01-04        |
| 2019-01-05        |
+-------------------+
Succeeded table:
+-------------------+
| success_date      |
+-------------------+
| 2018-12-30        |
| 2018-12-31        |
| 2019-01-01        |
| 2019-01-02        |
| 2019-01-03        |
| 2019-01-06        |
+-------------------+
Output: 
+--------------+--------------+--------------+
| period_state | start_date   | end_date     |
+--------------+--------------+--------------+
| succeeded    | 2019-01-01   | 2019-01-03   |
| failed       | 2019-01-04   | 2019-01-05   |
| succeeded    | 2019-01-06   | 2019-01-06   |
+--------------+--------------+--------------+
Explanation: 
The report ignored the system state in 2018 as we care about the system in the period 2019-01-01 to 2019-12-31.
From 2019-01-01 to 2019-01-03 all tasks succeeded and the system state was "succeeded".
From 2019-01-04 to 2019-01-05 all tasks failed and the system state was "failed".
From 2019-01-06 to 2019-01-06 all tasks succeeded and the system state was "succeeded"
``` 

### Hardcode
```py
import pandas as pd 
import numpy as np 

def report_contiguous_dates(failed: pd.DataFrame, succeeded: pd.DataFrame) -> pd.DataFrame: 
    start_Date = pd.to_datetime('2019-01-01') 
    end_Date = pd.to_datetime('2019-12-31') 
    succeeded['success_date'] = pd.to_datetime(succeeded['success_date']) 
    failed['fail_date'] = pd.to_datetime(failed['fail_date']) 
    succeeded = succeeded.loc[(start_Date <= succeeded['success_date']) & (succeeded['success_date'] <= end_Date)] 
    failed = failed.loc[(start_Date <= failed['fail_date']) & (failed['fail_date'] <= end_Date)] 
    succeeded = succeeded.rename(columns={'success_date': 'date'}) 
    succeeded['period_state'] = 'succeeded'
    failed = failed.rename(columns={'fail_date': 'date'})  
    failed['period_state'] = 'failed' 
    output = pd.concat([succeeded, failed]) 
    output = output.sort_values(['date'], ascending=[True])
    output['prev_period_state'] = output['period_state'].shift(1) 
    output['is_new_group'] = output['period_state'] != output['prev_period_state']
    output['is_new_group'] = output['is_new_group'].map({True: 1, False: 0})  
    output['group_num'] = output['is_new_group'].cumsum() 
    output = output.groupby('group_num').agg(
        start_date=('date', 'min'), 
        end_date=('date', 'max'), 
        period_state=('period_state', 'first')  
    ).reset_index() 
    output = output[['period_state', 'start_date', 'end_date']]    
    return output   
```

 ### Mapping Table 
 ```py
import pandas as pd
import numpy as np

def report_contiguous_dates(failed: pd.DataFrame, succeeded: pd.DataFrame) -> pd.DataFrame:
    # 1. Define the mapping table and convert to datetime
    mapping_table = pd.DataFrame({
        'start_Date': ['2019-01-01'],
        'end_Date':   ['2019-12-31']
    })
    mapping_table['start_Date'] = pd.to_datetime(mapping_table['start_Date'])
    mapping_table['end_Date'] = pd.to_datetime(mapping_table['end_Date'])
    
    succeeded['success_date'] = pd.to_datetime(succeeded['success_date'])
    failed['fail_date'] = pd.to_datetime(failed['fail_date'])
    
    # 2. Cross join the mapping table to both dataframes
    succeeded = succeeded.merge(mapping_table, how='cross')
    failed = failed.merge(mapping_table, how='cross')
    
    # 3. Filter based on the newly joined mapping dates
    succeeded = succeeded.loc[(succeeded['start_Date'] <= succeeded['success_date']) & 
                              (succeeded['success_date'] <= succeeded['end_Date'])]
    failed = failed.loc[(failed['start_Date'] <= failed['fail_date']) & 
                        (failed['fail_date'] <= failed['end_Date'])]
    
    # 4. Drop the mapping columns to clean up before concat
    succeeded = succeeded.drop(columns=['start_ Date', 'end_Date'])
    failed = failed.drop(columns=['start_Date', 'end_Date'])
    
    # 5. Standardize column names to unify the two data sources 
    succeeded = succeeded.rename(columns={'success_date': 'date'})
    succeeded['period_state'] = 'succeeded'
    
    failed = failed.rename(columns={'fail_date': 'date'})  
    failed['period_state'] = 'failed' 
    
    # 6. Combine both states into a single timeline and sort chronologically 
    output = pd.concat([succeeded, failed], ignore_index=True) 
    output = output.sort_values(['date'], ascending=[True])
    
    # 7. Create group number 
    output['prev_period_state'] = output['period_state'].shift(1) 
    output['is_new_group'] = output['period_state'] != output['prev_period_state']
    output['is_new_group'] = output['is_new_group'].map({True: 1, False: 0})  
    output['group_num'] = output['is_new_group'].cumsum() 
    
    # 8. Calculate the start, end, and state for each identified group 
    output = output.groupby('group_num').agg(
        start_date=('date', 'min'), 
        end_date=('date', 'max'), 
        period_state=('period_state', 'first')   
    ).reset_index() 
    
    # 9. Select and order final columns for output  
    output = output[['period_state', 'start_date', 'end_date']]     
    return output 
``` 

Here is the step-by-step Microsoft Fabric Dataflow Gen2 instructions 
![alt text](/FabricScreenshot/1225_overview.jpg)
[Report Contiguous Dates.pqt](/FabricWorkflow/Report Contiguous Dates.pqt)
